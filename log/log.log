15:05:17,498 [mainhread] io.netty.util.internal.PlatformDependent$Mpsc.<clinit>(PlatformDependent.java:1010)evel io.netty.util.internal.PlatformDependent$Mpsc.<clinit>(PlatformDependent.java:1010)ogger{32} - org.jctools-core.MpscChunkedArrayQueue: available 
15:05:17,532 [mainhread] io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:79)evel io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:79)ogger{32} - -Dio.netty.processId: 17958 (auto-detected) 
15:05:17,535 [mainhread] io.netty.util.NetUtil.<clinit>(NetUtil.java:136)evel io.netty.util.NetUtil.<clinit>(NetUtil.java:136)ogger{32} - -Djava.net.preferIPv4Stack: false 
15:05:17,535 [mainhread] io.netty.util.NetUtil.<clinit>(NetUtil.java:137)evel io.netty.util.NetUtil.<clinit>(NetUtil.java:137)ogger{32} - -Djava.net.preferIPv6Addresses: false 
15:05:17,538 [mainhread] io.netty.util.NetUtilInitializations.determineLoopback(NetUtilInitializations.java:129)evel io.netty.util.NetUtilInitializations.determineLoopback(NetUtilInitializations.java:129)ogger{32} - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1%lo0) 
15:05:17,538 [mainhread] io.netty.util.NetUtil$SoMaxConnAction.run(NetUtil.java:191)evel io.netty.util.NetUtil$SoMaxConnAction.run(NetUtil.java:191)ogger{32} - Failed to get SOMAXCONN from sysctl and file /proc/sys/net/core/somaxconn. Default: 128 
15:05:17,540 [mainhread] io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:101)evel io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:101)ogger{32} - -Dio.netty.machineId: f4:d4:88:ff:fe:69:32:c8 (auto-detected) 
15:05:17,547 [mainhread] io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:129)evel io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:129)ogger{32} - -Dio.netty.leakDetection.level: simple 
15:05:17,547 [mainhread] io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:130)evel io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:130)ogger{32} - -Dio.netty.leakDetection.targetRecords: 4 
15:05:17,563 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:157)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:157)ogger{32} - -Dio.netty.allocator.numHeapArenas: 20 
15:05:17,564 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:158)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:158)ogger{32} - -Dio.netty.allocator.numDirectArenas: 20 
15:05:17,564 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:160)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:160)ogger{32} - -Dio.netty.allocator.pageSize: 8192 
15:05:17,564 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:165)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:165)ogger{32} - -Dio.netty.allocator.maxOrder: 9 
15:05:17,564 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:169)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:169)ogger{32} - -Dio.netty.allocator.chunkSize: 4194304 
15:05:17,564 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:170)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:170)ogger{32} - -Dio.netty.allocator.smallCacheSize: 256 
15:05:17,565 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:171)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:171)ogger{32} - -Dio.netty.allocator.normalCacheSize: 64 
15:05:17,566 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:172)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:172)ogger{32} - -Dio.netty.allocator.maxCachedBufferCapacity: 32768 
15:05:17,566 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:173)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:173)ogger{32} - -Dio.netty.allocator.cacheTrimInterval: 8192 
15:05:17,566 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:174)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:174)ogger{32} - -Dio.netty.allocator.cacheTrimIntervalMillis: 0 
15:05:17,566 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:175)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:175)ogger{32} - -Dio.netty.allocator.useCacheForAllThreads: false 
15:05:17,567 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:176)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:176)ogger{32} - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023 
15:05:17,574 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:87)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:87)ogger{32} - -Dio.netty.allocator.type: pooled 
15:05:17,575 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:96)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:96)ogger{32} - -Dio.netty.threadLocalDirectBufferSize: 0 
15:05:17,576 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:99)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:99)ogger{32} - -Dio.netty.maxThreadLocalCharBufferSize: 16384 
15:05:17,586 [mainhread] com.github.trganda.TestServer.<init>(TestServer.java:50)evel com.github.trganda.TestServer.<init>(TestServer.java:50)ogger{32} - Test MySQL server listening on port 3306 
15:05:17,704 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$1.initChannel(TestServer.java:40)evel com.github.trganda.TestServer$1.initChannel(TestServer.java:40)ogger{32} - Initializing child channel 
15:05:17,728 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelActive(TestServer.java:82)evel com.github.trganda.TestServer$ServerHandler.channelActive(TestServer.java:82)ogger{32} - Server channel active 
15:05:17,739 [nioEventLoopGroup-3-1hread] io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:63)evel io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:63)ogger{32} - -Dio.netty.buffer.checkAccessible: true 
15:05:17,739 [nioEventLoopGroup-3-1hread] io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:64)evel io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:64)ogger{32} - -Dio.netty.buffer.checkBounds: true 
15:05:17,740 [nioEventLoopGroup-3-1hread] io.netty.util.ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory.newResourceLeakDetector(ResourceLeakDetectorFactory.java:196)evel io.netty.util.ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory.newResourceLeakDetector(ResourceLeakDetectorFactory.java:196)ogger{32} - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@4fd0a50 
15:05:17,750 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:85)evel io.netty.util.Recycler.<clinit>(Recycler.java:85)ogger{32} - -Dio.netty.recycler.maxCapacityPerThread: 4096 
15:05:17,750 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:86)evel io.netty.util.Recycler.<clinit>(Recycler.java:86)ogger{32} - -Dio.netty.recycler.ratio: 8 
15:05:17,750 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:87)evel io.netty.util.Recycler.<clinit>(Recycler.java:87)ogger{32} - -Dio.netty.recycler.chunkSize: 32 
15:05:17,751 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:88)evel io.netty.util.Recycler.<clinit>(Recycler.java:88)ogger{32} - -Dio.netty.recycler.blocking: false 
15:05:17,786 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleHandshakeResponse(TestServer.java:117)evel com.github.trganda.TestServer.handleHandshakeResponse(TestServer.java:117)ogger{32} - Received handshake response 
15:05:17,792 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: /* mysql-connector-java-8.0.28 (Revision: 7ff2161da3899f379fb3171b6538b191b1c5c7e2) */SELECT  @@session.auto_increment_increment AS auto_increment_increment, @@character_set_client AS character_set_client, @@character_set_connection AS character_set_connection, @@character_set_results AS character_set_results, @@character_set_server AS character_set_server, @@collation_server AS collation_server, @@collation_connection AS collation_connection, @@init_connect AS init_connect, @@interactive_timeout AS interactive_timeout, @@language AS language, @@license AS license, @@lower_case_table_names AS lower_case_table_names, @@max_allowed_packet AS max_allowed_packet, @@net_write_timeout AS net_write_timeout, @@performance_schema AS performance_schema, @@query_cache_size AS query_cache_size, @@query_cache_type AS query_cache_type, @@sql_mode AS sql_mode, @@system_time_zone AS system_time_zone, @@time_zone AS time_zone, @@tx_isolation AS transaction_isolation, @@wait_timeout AS wait_timeout 
15:05:17,813 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SET NAMES utf8mb4 
15:05:17,815 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SET autocommit=1 
15:05:17,819 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SET sql_mode='STRICT_TRANS_TABLES' 
15:05:17,826 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SELECT 1 
15:05:17,842 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelRead(TestServer.java:110)evel com.github.trganda.TestServer$ServerHandler.channelRead(TestServer.java:110)ogger{32} - Received message: com.github.trganda.codec.CommandPacket@19e322f 
15:05:17,844 [nioEventLoopGroup-3-1hread] io.netty.channel.DefaultChannelPipeline.onUnhandledInboundException(DefaultChannelPipeline.java:1152)evel io.netty.channel.DefaultChannelPipeline.onUnhandledInboundException(DefaultChannelPipeline.java:1152)ogger{32} - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
15:05:17,849 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelInactive(TestServer.java:98)evel com.github.trganda.TestServer$ServerHandler.channelInactive(TestServer.java:98)ogger{32} - Server channel inactive 
15:05:19,953 [nioEventLoopGroup-3-1hread] io.netty.buffer.PoolThreadCache.free(PoolThreadCache.java:227)evel io.netty.buffer.PoolThreadCache.free(PoolThreadCache.java:227)ogger{32} - Freed 28 thread-local buffer(s) from thread: nioEventLoopGroup-3-1 
15:05:40,418 [mainhread] io.netty.util.internal.logging.InternalLoggerFactory.useSlf4JLoggerFactory(InternalLoggerFactory.java:63)evel io.netty.util.internal.logging.InternalLoggerFactory.useSlf4JLoggerFactory(InternalLoggerFactory.java:63)ogger{32} - Using SLF4J as the default logging framework 
15:05:40,420 [mainhread] io.netty.channel.MultithreadEventLoopGroup.<clinit>(MultithreadEventLoopGroup.java:44)evel io.netty.channel.MultithreadEventLoopGroup.<clinit>(MultithreadEventLoopGroup.java:44)ogger{32} - -Dio.netty.eventLoopThreads: 20 
15:05:40,435 [mainhread] io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:100)evel io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:100)ogger{32} - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024 
15:05:40,436 [mainhread] io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:101)evel io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:101)ogger{32} - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096 
15:05:40,454 [mainhread] io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0(PlatformDependent0.java:496)evel io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0(PlatformDependent0.java:496)ogger{32} - -Dio.netty.noUnsafe: false 
15:05:40,454 [mainhread] io.netty.util.internal.PlatformDependent0.javaVersion0(PlatformDependent0.java:1000)evel io.netty.util.internal.PlatformDependent0.javaVersion0(PlatformDependent0.java:1000)ogger{32} - Java version: 8 
15:05:40,456 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:137)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:137)ogger{32} - sun.misc.Unsafe.theUnsafe: available 
15:05:40,456 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:161)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:161)ogger{32} - sun.misc.Unsafe.copyMemory: available 
15:05:40,458 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:193)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:193)ogger{32} - sun.misc.Unsafe.storeFence: available 
15:05:40,458 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:236)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:236)ogger{32} - java.nio.Buffer.address: available 
15:05:40,459 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:307)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:307)ogger{32} - direct buffer constructor: available 
15:05:40,459 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:385)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:385)ogger{32} - java.nio.Bits.unaligned: available, true 
15:05:40,460 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:459)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:459)ogger{32} - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9 
15:05:40,460 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:482)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:482)ogger{32} - java.nio.DirectByteBuffer.<init>(long, int): available 
15:05:40,460 [mainhread] io.netty.util.internal.PlatformDependent.unsafeUnavailabilityCause0(PlatformDependent.java:1159)evel io.netty.util.internal.PlatformDependent.unsafeUnavailabilityCause0(PlatformDependent.java:1159)ogger{32} - sun.misc.Unsafe: available 
15:05:40,461 [mainhread] io.netty.util.internal.PlatformDependent.tmpdir0(PlatformDependent.java:1289)evel io.netty.util.internal.PlatformDependent.tmpdir0(PlatformDependent.java:1289)ogger{32} - -Dio.netty.tmpdir: /var/folders/zq/bnfkv60s36z0lqyt0csfv68m0000gn/T (java.io.tmpdir) 
15:05:40,461 [mainhread] io.netty.util.internal.PlatformDependent.bitMode0(PlatformDependent.java:1368)evel io.netty.util.internal.PlatformDependent.bitMode0(PlatformDependent.java:1368)ogger{32} - -Dio.netty.bitMode: 64 (sun.arch.data.model) 
15:05:40,462 [mainhread] io.netty.util.internal.PlatformDependent.isOsx0(PlatformDependent.java:1127)evel io.netty.util.internal.PlatformDependent.isOsx0(PlatformDependent.java:1127)ogger{32} - Platform: MacOS 
15:05:40,464 [mainhread] io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:178)evel io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:178)ogger{32} - -Dio.netty.maxDirectMemory: 15271460864 bytes 
15:05:40,464 [mainhread] io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:185)evel io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:185)ogger{32} - -Dio.netty.uninitializedArrayAllocationThreshold: -1 
15:05:40,465 [mainhread] io.netty.util.internal.CleanerJava6.<clinit>(CleanerJava6.java:92)evel io.netty.util.internal.CleanerJava6.<clinit>(CleanerJava6.java:92)ogger{32} - java.nio.ByteBuffer.cleaner(): available 
15:05:40,465 [mainhread] io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:205)evel io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:205)ogger{32} - -Dio.netty.noPreferDirect: false 
15:05:40,465 [mainhread] io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:110)evel io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:110)ogger{32} - -Dio.netty.noKeySetOptimization: false 
15:05:40,466 [mainhread] io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:111)evel io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:111)ogger{32} - -Dio.netty.selectorAutoRebuildThreshold: 512 
15:05:40,470 [mainhread] io.netty.util.internal.PlatformDependent$Mpsc.<clinit>(PlatformDependent.java:1010)evel io.netty.util.internal.PlatformDependent$Mpsc.<clinit>(PlatformDependent.java:1010)ogger{32} - org.jctools-core.MpscChunkedArrayQueue: available 
15:05:40,504 [mainhread] io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:79)evel io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:79)ogger{32} - -Dio.netty.processId: 17972 (auto-detected) 
15:05:40,508 [mainhread] io.netty.util.NetUtil.<clinit>(NetUtil.java:136)evel io.netty.util.NetUtil.<clinit>(NetUtil.java:136)ogger{32} - -Djava.net.preferIPv4Stack: false 
15:05:40,508 [mainhread] io.netty.util.NetUtil.<clinit>(NetUtil.java:137)evel io.netty.util.NetUtil.<clinit>(NetUtil.java:137)ogger{32} - -Djava.net.preferIPv6Addresses: false 
15:05:40,510 [mainhread] io.netty.util.NetUtilInitializations.determineLoopback(NetUtilInitializations.java:129)evel io.netty.util.NetUtilInitializations.determineLoopback(NetUtilInitializations.java:129)ogger{32} - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1%lo0) 
15:05:40,511 [mainhread] io.netty.util.NetUtil$SoMaxConnAction.run(NetUtil.java:191)evel io.netty.util.NetUtil$SoMaxConnAction.run(NetUtil.java:191)ogger{32} - Failed to get SOMAXCONN from sysctl and file /proc/sys/net/core/somaxconn. Default: 128 
15:05:40,513 [mainhread] io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:101)evel io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:101)ogger{32} - -Dio.netty.machineId: f4:d4:88:ff:fe:69:32:c8 (auto-detected) 
15:05:40,519 [mainhread] io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:129)evel io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:129)ogger{32} - -Dio.netty.leakDetection.level: simple 
15:05:40,520 [mainhread] io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:130)evel io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:130)ogger{32} - -Dio.netty.leakDetection.targetRecords: 4 
15:05:40,535 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:157)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:157)ogger{32} - -Dio.netty.allocator.numHeapArenas: 20 
15:05:40,536 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:158)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:158)ogger{32} - -Dio.netty.allocator.numDirectArenas: 20 
15:05:40,536 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:160)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:160)ogger{32} - -Dio.netty.allocator.pageSize: 8192 
15:05:40,536 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:165)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:165)ogger{32} - -Dio.netty.allocator.maxOrder: 9 
15:05:40,536 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:169)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:169)ogger{32} - -Dio.netty.allocator.chunkSize: 4194304 
15:05:40,537 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:170)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:170)ogger{32} - -Dio.netty.allocator.smallCacheSize: 256 
15:05:40,537 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:171)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:171)ogger{32} - -Dio.netty.allocator.normalCacheSize: 64 
15:05:40,538 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:172)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:172)ogger{32} - -Dio.netty.allocator.maxCachedBufferCapacity: 32768 
15:05:40,539 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:173)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:173)ogger{32} - -Dio.netty.allocator.cacheTrimInterval: 8192 
15:05:40,539 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:174)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:174)ogger{32} - -Dio.netty.allocator.cacheTrimIntervalMillis: 0 
15:05:40,539 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:175)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:175)ogger{32} - -Dio.netty.allocator.useCacheForAllThreads: false 
15:05:40,539 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:176)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:176)ogger{32} - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023 
15:05:40,547 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:87)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:87)ogger{32} - -Dio.netty.allocator.type: pooled 
15:05:40,548 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:96)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:96)ogger{32} - -Dio.netty.threadLocalDirectBufferSize: 0 
15:05:40,548 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:99)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:99)ogger{32} - -Dio.netty.maxThreadLocalCharBufferSize: 16384 
15:05:40,559 [mainhread] com.github.trganda.TestServer.<init>(TestServer.java:50)evel com.github.trganda.TestServer.<init>(TestServer.java:50)ogger{32} - Test MySQL server listening on port 3306 
15:05:40,678 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$1.initChannel(TestServer.java:40)evel com.github.trganda.TestServer$1.initChannel(TestServer.java:40)ogger{32} - Initializing child channel 
15:05:40,701 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelActive(TestServer.java:82)evel com.github.trganda.TestServer$ServerHandler.channelActive(TestServer.java:82)ogger{32} - Server channel active 
15:05:40,710 [nioEventLoopGroup-3-1hread] io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:63)evel io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:63)ogger{32} - -Dio.netty.buffer.checkAccessible: true 
15:05:40,710 [nioEventLoopGroup-3-1hread] io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:64)evel io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:64)ogger{32} - -Dio.netty.buffer.checkBounds: true 
15:05:40,711 [nioEventLoopGroup-3-1hread] io.netty.util.ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory.newResourceLeakDetector(ResourceLeakDetectorFactory.java:196)evel io.netty.util.ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory.newResourceLeakDetector(ResourceLeakDetectorFactory.java:196)ogger{32} - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@7ae17682 
15:05:40,718 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:85)evel io.netty.util.Recycler.<clinit>(Recycler.java:85)ogger{32} - -Dio.netty.recycler.maxCapacityPerThread: 4096 
15:05:40,718 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:86)evel io.netty.util.Recycler.<clinit>(Recycler.java:86)ogger{32} - -Dio.netty.recycler.ratio: 8 
15:05:40,718 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:87)evel io.netty.util.Recycler.<clinit>(Recycler.java:87)ogger{32} - -Dio.netty.recycler.chunkSize: 32 
15:05:40,718 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:88)evel io.netty.util.Recycler.<clinit>(Recycler.java:88)ogger{32} - -Dio.netty.recycler.blocking: false 
15:05:40,757 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleHandshakeResponse(TestServer.java:117)evel com.github.trganda.TestServer.handleHandshakeResponse(TestServer.java:117)ogger{32} - Received handshake response 
15:05:40,762 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: /* mysql-connector-java-8.0.28 (Revision: 7ff2161da3899f379fb3171b6538b191b1c5c7e2) */SELECT  @@session.auto_increment_increment AS auto_increment_increment, @@character_set_client AS character_set_client, @@character_set_connection AS character_set_connection, @@character_set_results AS character_set_results, @@character_set_server AS character_set_server, @@collation_server AS collation_server, @@collation_connection AS collation_connection, @@init_connect AS init_connect, @@interactive_timeout AS interactive_timeout, @@language AS language, @@license AS license, @@lower_case_table_names AS lower_case_table_names, @@max_allowed_packet AS max_allowed_packet, @@net_write_timeout AS net_write_timeout, @@performance_schema AS performance_schema, @@query_cache_size AS query_cache_size, @@query_cache_type AS query_cache_type, @@sql_mode AS sql_mode, @@system_time_zone AS system_time_zone, @@time_zone AS time_zone, @@tx_isolation AS transaction_isolation, @@wait_timeout AS wait_timeout 
15:05:40,782 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SET NAMES utf8mb4 
15:05:40,784 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SET autocommit=1 
15:05:40,787 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SET sql_mode='STRICT_TRANS_TABLES' 
15:05:40,795 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:130)evel com.github.trganda.TestServer.handleQuery(TestServer.java:130)ogger{32} - Received query: SELECT 1 
15:05:40,814 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelRead(TestServer.java:110)evel com.github.trganda.TestServer$ServerHandler.channelRead(TestServer.java:110)ogger{32} - Received message: com.github.trganda.codec.CommandPacket@6e749c74 
15:05:40,816 [nioEventLoopGroup-3-1hread] io.netty.channel.DefaultChannelPipeline.onUnhandledInboundException(DefaultChannelPipeline.java:1152)evel io.netty.channel.DefaultChannelPipeline.onUnhandledInboundException(DefaultChannelPipeline.java:1152)ogger{32} - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:750)
15:05:40,822 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelInactive(TestServer.java:98)evel com.github.trganda.TestServer$ServerHandler.channelInactive(TestServer.java:98)ogger{32} - Server channel inactive 
15:05:42,856 [nioEventLoopGroup-3-1hread] io.netty.buffer.PoolThreadCache.free(PoolThreadCache.java:227)evel io.netty.buffer.PoolThreadCache.free(PoolThreadCache.java:227)ogger{32} - Freed 28 thread-local buffer(s) from thread: nioEventLoopGroup-3-1 
15:28:17,768 [mainhread] io.netty.util.internal.logging.InternalLoggerFactory.useSlf4JLoggerFactory(InternalLoggerFactory.java:63)evel io.netty.util.internal.logging.InternalLoggerFactory.useSlf4JLoggerFactory(InternalLoggerFactory.java:63)ogger{32} - Using SLF4J as the default logging framework 
15:28:17,770 [mainhread] io.netty.channel.MultithreadEventLoopGroup.<clinit>(MultithreadEventLoopGroup.java:44)evel io.netty.channel.MultithreadEventLoopGroup.<clinit>(MultithreadEventLoopGroup.java:44)ogger{32} - -Dio.netty.eventLoopThreads: 20 
15:28:17,785 [mainhread] io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:100)evel io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:100)ogger{32} - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024 
15:28:17,785 [mainhread] io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:101)evel io.netty.util.internal.InternalThreadLocalMap.<clinit>(InternalThreadLocalMap.java:101)ogger{32} - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096 
15:28:17,801 [mainhread] io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0(PlatformDependent0.java:496)evel io.netty.util.internal.PlatformDependent0.explicitNoUnsafeCause0(PlatformDependent0.java:496)ogger{32} - -Dio.netty.noUnsafe: false 
15:28:17,802 [mainhread] io.netty.util.internal.PlatformDependent0.javaVersion0(PlatformDependent0.java:1000)evel io.netty.util.internal.PlatformDependent0.javaVersion0(PlatformDependent0.java:1000)ogger{32} - Java version: 8 
15:28:17,804 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:137)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:137)ogger{32} - sun.misc.Unsafe.theUnsafe: available 
15:28:17,804 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:161)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:161)ogger{32} - sun.misc.Unsafe.copyMemory: available 
15:28:17,804 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:193)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:193)ogger{32} - sun.misc.Unsafe.storeFence: available 
15:28:17,805 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:236)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:236)ogger{32} - java.nio.Buffer.address: available 
15:28:17,806 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:307)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:307)ogger{32} - direct buffer constructor: available 
15:28:17,807 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:385)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:385)ogger{32} - java.nio.Bits.unaligned: available, true 
15:28:17,807 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:459)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:459)ogger{32} - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9 
15:28:17,808 [mainhread] io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:482)evel io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:482)ogger{32} - java.nio.DirectByteBuffer.<init>(long, int): available 
15:28:17,808 [mainhread] io.netty.util.internal.PlatformDependent.unsafeUnavailabilityCause0(PlatformDependent.java:1159)evel io.netty.util.internal.PlatformDependent.unsafeUnavailabilityCause0(PlatformDependent.java:1159)ogger{32} - sun.misc.Unsafe: available 
15:28:17,809 [mainhread] io.netty.util.internal.PlatformDependent.tmpdir0(PlatformDependent.java:1289)evel io.netty.util.internal.PlatformDependent.tmpdir0(PlatformDependent.java:1289)ogger{32} - -Dio.netty.tmpdir: /var/folders/zq/bnfkv60s36z0lqyt0csfv68m0000gn/T (java.io.tmpdir) 
15:28:17,809 [mainhread] io.netty.util.internal.PlatformDependent.bitMode0(PlatformDependent.java:1368)evel io.netty.util.internal.PlatformDependent.bitMode0(PlatformDependent.java:1368)ogger{32} - -Dio.netty.bitMode: 64 (sun.arch.data.model) 
15:28:17,810 [mainhread] io.netty.util.internal.PlatformDependent.isOsx0(PlatformDependent.java:1127)evel io.netty.util.internal.PlatformDependent.isOsx0(PlatformDependent.java:1127)ogger{32} - Platform: MacOS 
15:28:17,815 [mainhread] io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:178)evel io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:178)ogger{32} - -Dio.netty.maxDirectMemory: 15271460864 bytes 
15:28:17,815 [mainhread] io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:185)evel io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:185)ogger{32} - -Dio.netty.uninitializedArrayAllocationThreshold: -1 
15:28:17,815 [mainhread] io.netty.util.internal.CleanerJava6.<clinit>(CleanerJava6.java:92)evel io.netty.util.internal.CleanerJava6.<clinit>(CleanerJava6.java:92)ogger{32} - java.nio.ByteBuffer.cleaner(): available 
15:28:17,815 [mainhread] io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:205)evel io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:205)ogger{32} - -Dio.netty.noPreferDirect: false 
15:28:17,816 [mainhread] io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:110)evel io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:110)ogger{32} - -Dio.netty.noKeySetOptimization: false 
15:28:17,816 [mainhread] io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:111)evel io.netty.channel.nio.NioEventLoop.<clinit>(NioEventLoop.java:111)ogger{32} - -Dio.netty.selectorAutoRebuildThreshold: 512 
15:28:17,822 [mainhread] io.netty.util.internal.PlatformDependent$Mpsc.<clinit>(PlatformDependent.java:1010)evel io.netty.util.internal.PlatformDependent$Mpsc.<clinit>(PlatformDependent.java:1010)ogger{32} - org.jctools-core.MpscChunkedArrayQueue: available 
15:28:17,855 [mainhread] io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:79)evel io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:79)ogger{32} - -Dio.netty.processId: 18187 (auto-detected) 
15:28:17,858 [mainhread] io.netty.util.NetUtil.<clinit>(NetUtil.java:136)evel io.netty.util.NetUtil.<clinit>(NetUtil.java:136)ogger{32} - -Djava.net.preferIPv4Stack: false 
15:28:17,858 [mainhread] io.netty.util.NetUtil.<clinit>(NetUtil.java:137)evel io.netty.util.NetUtil.<clinit>(NetUtil.java:137)ogger{32} - -Djava.net.preferIPv6Addresses: false 
15:28:17,860 [mainhread] io.netty.util.NetUtilInitializations.determineLoopback(NetUtilInitializations.java:129)evel io.netty.util.NetUtilInitializations.determineLoopback(NetUtilInitializations.java:129)ogger{32} - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1%lo0) 
15:28:17,861 [mainhread] io.netty.util.NetUtil$SoMaxConnAction.run(NetUtil.java:191)evel io.netty.util.NetUtil$SoMaxConnAction.run(NetUtil.java:191)ogger{32} - Failed to get SOMAXCONN from sysctl and file /proc/sys/net/core/somaxconn. Default: 128 
15:28:17,863 [mainhread] io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:101)evel io.netty.channel.DefaultChannelId.<clinit>(DefaultChannelId.java:101)ogger{32} - -Dio.netty.machineId: f4:d4:88:ff:fe:69:32:c8 (auto-detected) 
15:28:17,870 [mainhread] io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:129)evel io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:129)ogger{32} - -Dio.netty.leakDetection.level: simple 
15:28:17,870 [mainhread] io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:130)evel io.netty.util.ResourceLeakDetector.<clinit>(ResourceLeakDetector.java:130)ogger{32} - -Dio.netty.leakDetection.targetRecords: 4 
15:28:17,887 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:157)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:157)ogger{32} - -Dio.netty.allocator.numHeapArenas: 20 
15:28:17,887 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:158)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:158)ogger{32} - -Dio.netty.allocator.numDirectArenas: 20 
15:28:17,887 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:160)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:160)ogger{32} - -Dio.netty.allocator.pageSize: 8192 
15:28:17,887 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:165)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:165)ogger{32} - -Dio.netty.allocator.maxOrder: 9 
15:28:17,888 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:169)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:169)ogger{32} - -Dio.netty.allocator.chunkSize: 4194304 
15:28:17,888 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:170)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:170)ogger{32} - -Dio.netty.allocator.smallCacheSize: 256 
15:28:17,888 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:171)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:171)ogger{32} - -Dio.netty.allocator.normalCacheSize: 64 
15:28:17,890 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:172)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:172)ogger{32} - -Dio.netty.allocator.maxCachedBufferCapacity: 32768 
15:28:17,890 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:173)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:173)ogger{32} - -Dio.netty.allocator.cacheTrimInterval: 8192 
15:28:17,890 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:174)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:174)ogger{32} - -Dio.netty.allocator.cacheTrimIntervalMillis: 0 
15:28:17,890 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:175)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:175)ogger{32} - -Dio.netty.allocator.useCacheForAllThreads: false 
15:28:17,890 [mainhread] io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:176)evel io.netty.buffer.PooledByteBufAllocator.<clinit>(PooledByteBufAllocator.java:176)ogger{32} - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023 
15:28:17,899 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:87)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:87)ogger{32} - -Dio.netty.allocator.type: pooled 
15:28:17,900 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:96)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:96)ogger{32} - -Dio.netty.threadLocalDirectBufferSize: 0 
15:28:17,900 [mainhread] io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:99)evel io.netty.buffer.ByteBufUtil.<clinit>(ByteBufUtil.java:99)ogger{32} - -Dio.netty.maxThreadLocalCharBufferSize: 16384 
15:28:17,912 [mainhread] com.github.trganda.TestServer.<init>(TestServer.java:51)evel com.github.trganda.TestServer.<init>(TestServer.java:51)ogger{32} - Test MySQL server listening on port 3306 
15:28:18,038 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$1.initChannel(TestServer.java:41)evel com.github.trganda.TestServer$1.initChannel(TestServer.java:41)ogger{32} - Initializing child channel 
15:28:18,063 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelActive(TestServer.java:83)evel com.github.trganda.TestServer$ServerHandler.channelActive(TestServer.java:83)ogger{32} - Server channel active 
15:28:18,074 [nioEventLoopGroup-3-1hread] io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:63)evel io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:63)ogger{32} - -Dio.netty.buffer.checkAccessible: true 
15:28:18,074 [nioEventLoopGroup-3-1hread] io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:64)evel io.netty.buffer.AbstractByteBuf.<clinit>(AbstractByteBuf.java:64)ogger{32} - -Dio.netty.buffer.checkBounds: true 
15:28:18,075 [nioEventLoopGroup-3-1hread] io.netty.util.ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory.newResourceLeakDetector(ResourceLeakDetectorFactory.java:196)evel io.netty.util.ResourceLeakDetectorFactory$DefaultResourceLeakDetectorFactory.newResourceLeakDetector(ResourceLeakDetectorFactory.java:196)ogger{32} - Loaded default ResourceLeakDetector: io.netty.util.ResourceLeakDetector@77fe1f01 
15:28:18,087 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:85)evel io.netty.util.Recycler.<clinit>(Recycler.java:85)ogger{32} - -Dio.netty.recycler.maxCapacityPerThread: 4096 
15:28:18,087 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:86)evel io.netty.util.Recycler.<clinit>(Recycler.java:86)ogger{32} - -Dio.netty.recycler.ratio: 8 
15:28:18,088 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:87)evel io.netty.util.Recycler.<clinit>(Recycler.java:87)ogger{32} - -Dio.netty.recycler.chunkSize: 32 
15:28:18,088 [nioEventLoopGroup-3-1hread] io.netty.util.Recycler.<clinit>(Recycler.java:88)evel io.netty.util.Recycler.<clinit>(Recycler.java:88)ogger{32} - -Dio.netty.recycler.blocking: false 
15:28:18,127 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleHandshakeResponse(TestServer.java:140)evel com.github.trganda.TestServer.handleHandshakeResponse(TestServer.java:140)ogger{32} - Received handshake response 
15:28:18,133 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:153)evel com.github.trganda.TestServer.handleQuery(TestServer.java:153)ogger{32} - Received query: /* mysql-connector-java-8.0.28 (Revision: 7ff2161da3899f379fb3171b6538b191b1c5c7e2) */SELECT  @@session.auto_increment_increment AS auto_increment_increment, @@character_set_client AS character_set_client, @@character_set_connection AS character_set_connection, @@character_set_results AS character_set_results, @@character_set_server AS character_set_server, @@collation_server AS collation_server, @@collation_connection AS collation_connection, @@init_connect AS init_connect, @@interactive_timeout AS interactive_timeout, @@language AS language, @@license AS license, @@lower_case_table_names AS lower_case_table_names, @@max_allowed_packet AS max_allowed_packet, @@net_write_timeout AS net_write_timeout, @@performance_schema AS performance_schema, @@query_cache_size AS query_cache_size, @@query_cache_type AS query_cache_type, @@sql_mode AS sql_mode, @@system_time_zone AS system_time_zone, @@time_zone AS time_zone, @@tx_isolation AS transaction_isolation, @@wait_timeout AS wait_timeout 
15:28:18,155 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:153)evel com.github.trganda.TestServer.handleQuery(TestServer.java:153)ogger{32} - Received query: SET NAMES utf8mb4 
15:28:18,157 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:153)evel com.github.trganda.TestServer.handleQuery(TestServer.java:153)ogger{32} - Received query: SET autocommit=1 
15:28:18,162 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:153)evel com.github.trganda.TestServer.handleQuery(TestServer.java:153)ogger{32} - Received query: SET sql_mode='STRICT_TRANS_TABLES' 
15:28:18,170 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer.handleQuery(TestServer.java:153)evel com.github.trganda.TestServer.handleQuery(TestServer.java:153)ogger{32} - Received query: SELECT 1 
15:28:18,189 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelRead(TestServer.java:111)evel com.github.trganda.TestServer$ServerHandler.channelRead(TestServer.java:111)ogger{32} - Received message: com.github.trganda.codec.CommandPacket@4f0829e7 
15:28:18,190 [nioEventLoopGroup-3-1hread] com.github.trganda.TestServer$ServerHandler.channelInactive(TestServer.java:99)evel com.github.trganda.TestServer$ServerHandler.channelInactive(TestServer.java:99)ogger{32} - Server channel inactive 
15:28:20,212 [nioEventLoopGroup-3-1hread] io.netty.buffer.PoolThreadCache.free(PoolThreadCache.java:227)evel io.netty.buffer.PoolThreadCache.free(PoolThreadCache.java:227)ogger{32} - Freed 28 thread-local buffer(s) from thread: nioEventLoopGroup-3-1 
